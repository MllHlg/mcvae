{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(os.getcwd() + '/../src')\n",
    "from src.mcvae import pytorch_modules, utilities, preprocessing, plot, diagnostics\n",
    "\n",
    "DEVICE = pytorch_modules.DEVICE\n",
    "print(f\"Running on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data creation\n",
    "We are going to create a $3$-channel dataset with $4$ features each, starting from $2$ latent dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Nobs = 500\n",
    "n_channels = 3\n",
    "n_feats = 4\n",
    "true_lat_dims = 2\n",
    "fit_lat_dims = 5\n",
    "snr=10\n",
    "\n",
    "np.random.seed(7)\n",
    "z = np.random.randn(Nobs, true_lat_dims)\n",
    "z_test = np.random.randn(Nobs, true_lat_dims)\n",
    "\n",
    "generator = pytorch_modules.ScenarioGenerator(\n",
    "    lat_dim=true_lat_dims,\n",
    "    n_channels=n_channels,\n",
    "    n_feats=n_feats,\n",
    ")\n",
    "\n",
    "preprocpars = {'remove_mean': True, 'normalize': True, 'whitening': False}\n",
    "\n",
    "x_ = generator(z)\n",
    "x, x_noisy = utilities.preprocess_and_add_noise(x_, snr=snr)\n",
    "#x = mcvae.utilities.ltotensor(\n",
    "#    mcvae.preprocessing.preprocess(x_, **preprocpars)\n",
    "#)\n",
    "# Send to GPU (if possible)\n",
    "X = [c.to(DEVICE) for c in x] if torch.cuda.is_available() else x\n",
    "\n",
    "# x_test_ = generator(z_test)\n",
    "# x_test = mcvae.utilities.ltotensor(\n",
    "#     mcvae.preprocessing.preprocess(x_test_, **preprocpars)\n",
    "# )\n",
    "# X_test = [c.to(DEVICE) for c in x_test] if torch.cuda.is_available() else x_test\n",
    "\n",
    "###################\n",
    "## Model Fitting ##\n",
    "###################\n",
    "init_dict = {\n",
    "    'n_channels': len(x),\n",
    "    'lat_dim': fit_lat_dims,\n",
    "    'n_feats': tuple([i.shape[1] for i in X]),\n",
    "}\n",
    "\n",
    "adam_lr = 1e-3\n",
    "n_epochs = 20000\n",
    "\n",
    "model = {}\n",
    "\n",
    "# Multi-Channel VAE\n",
    "torch.manual_seed(24)\n",
    "model['mcvae'] = pytorch_modules.MultiChannelBase(\n",
    "    **init_dict,\n",
    "    model_name_dict={**init_dict, 'adam_lr': adam_lr, 'snr': snr},\n",
    ")\n",
    "\n",
    "# Sparse Multi-Channel VAE\n",
    "torch.manual_seed(24)\n",
    "model['smcvae'] = pytorch_modules.MultiChannelSparseVAE(\n",
    "    **init_dict,\n",
    "    model_name_dict={**init_dict, 'adam_lr': adam_lr, 'snr': snr},\n",
    ")\n",
    "\n",
    "for current_model in model.keys():\n",
    "\n",
    "    model[current_model].to(DEVICE)\n",
    "\n",
    "    modelpath = model[current_model].model_name + '.pt'\n",
    "    if os.path.exists(modelpath):\n",
    "        print(f\"Loading {modelpath}\")\n",
    "        mdict = torch.load(modelpath, map_location=DEVICE)\n",
    "        model[current_model].load_state_dict(mdict['state_dict'])\n",
    "        model[current_model].optimizer = torch.optim.Adam(model[current_model].parameters())\n",
    "        model[current_model].optimizer.load_state_dict(mdict['optimizer'])\n",
    "        model[current_model].loss = mdict['loss']\n",
    "        model[current_model].eval()\n",
    "        del mdict\n",
    "    else:\n",
    "        print(f\"Fitting {modelpath}\")\n",
    "        model[current_model].init_loss()\n",
    "        model[current_model].optimizer = torch.optim.Adam(model[current_model].parameters(), lr=adam_lr)\n",
    "        model[current_model].optimize(epochs=n_epochs, data=X)\n",
    "        print(\"Refine optimization...\")\n",
    "        for pg in model[current_model].optimizer.param_groups:\n",
    "            pg['lr'] *= 0.1\n",
    "        model[current_model].optimize(epochs=n_epochs, data=X)\n",
    "        utilities.save_model(model[current_model])\n",
    "\n",
    "# Output of the models\n",
    "pred = {}  # Prediction\n",
    "z = {}     # Latent Space\n",
    "g = {}     # Generative Parameters\n",
    "x_hat = {}  # reconstructed channels\n",
    "\n",
    "for m in model.keys():\n",
    "    diagnostics.plot_loss(model[m])\n",
    "    pred[m] = model[m](X)\n",
    "    x_hat[m] = model[m].reconstruct(X)\n",
    "    z[m] = np.array([pred[m]['qzx'][i].loc.detach().numpy() for i in range(n_channels)]).reshape(-1)\n",
    "    g[m] = np.array([model[m].W_out[i].weight.detach().numpy() for i in range(n_channels)]).reshape(-1)\n",
    "\n",
    "plot.lsplom(utilities.ltonumpy(x), title=f'Ground truth')\n",
    "plot.lsplom(utilities.ltonumpy(x_noisy), title=f'Noisy data fitted by the models (snr={snr})')\n",
    "for m in model.keys():\n",
    "    plot.lsplom(utilities.ltonumpy(x_hat[m]), title=f'Reconstructed with {m} model')\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist([z['smcvae'], z['mcvae']], bins=20, color=['k', 'gray'])\n",
    "plt.legend(['Sparse', 'Non sparse'])\n",
    "plt.title(r'Latent dimensions distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Value')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist([g['smcvae'], g['mcvae']], bins=20, color=['k', 'gray'])\n",
    "plt.legend(['Sparse', 'Non sparse'])\n",
    "plt.title(r'Generative parameters $\\mathbf{\\theta} = \\{\\mathbf{\\theta}_1 \\ldots \\mathbf{\\theta}_C\\}$')\n",
    "plt.xlabel('Value')\n",
    "\n",
    "\n",
    "# Show dropout effect\n",
    "do = np.sort(model['smcvae'].dropout.detach().numpy().reshape(-1))\n",
    "plt.figure()\n",
    "plt.bar(range(len(do)), do)\n",
    "plt.suptitle(f'Dropout probability of {fit_lat_dims} fitted latent dimensions in Sparse Model')\n",
    "plt.title(f'({true_lat_dims} true latent dimensions)')\n",
    "\n",
    "plt.show()\n",
    "print(\"See you!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}